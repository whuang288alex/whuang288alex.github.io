<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-rbsA2VBKQhggwzxH7pPCaAqO46MgnOM80zW1RWuH61DGLwZJEdK2Kadq2F9CUG65" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.10.2/font/bootstrap-icons.css">
    <title>Sign Language Detection</title>
</head>
<body>
    <!-- navbar section -->
    <nav class="navbar navbar-expand-lg bg-dark navbar-dark py-3 fixed-top">
        <div class="container">
            <a href="#" class="navbar-brand">Sign Language Detection</a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navmenu">
                <span class="navbar-toggler-icon"></span>
            </button>

            <div class="collapse navbar-collapse" id="navmenu">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item">
                        <a href="#gifs" class="nav-link">Result</a>
                    </li>
                    <li class="nav-item">
                        <a href="#intro" class="nav-link">Introduction</a>
                    </li>
                    <li class="nav-item">
                        <a href="#dataset" class="nav-link">Dataset</a>
                    </li>
                    <li class="nav-item">
                        <a href="#method" class="nav-link">Method</a>
                    </li>
                    <li class="nav-item">
                        <a href="#cite" class="nav-link">Citation</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>
    <section class="bg-dark">
        <h1></h1><br>
        <h1></h1>
    </section>
    <!-- start -->
    <section class="bg-dark text-light p-5 pb-lg-0 pt-lg-10 text-center text-sm-start">
        <div class="container">
            <div class="d-sm-flex align-items-center justify-content-between">
                <div>
                    <h1><span class="text-warning">Sign Language </span>Detection</h1>
                    <p class="lead my-4">
                        CS639 Computer Vision FA22 Final Project<br>
                        Alex Huang (whuang288@wisc.edu)<br>
                        Xizheng Yu (xyu354@wisc.edu)
                    </p>
                    <a href="https://github.com/whuang288alex/sign_language/" class="btn btn-outline-light btn-lg mt-3">
                        <i class="bi bi-github"></i> GitHub
                    </a>
                    <a href="https://youtu.be/JhRWBNDdwL0" class="btn btn-danger btn-lg mt-3">
                        <i class="bi bi-youtube"></i> YouTube
                    </a>
                </div>
                <img class="img-fluid w-50 d-none d-sm-block" src="./img/1_hands.png" alt=""/>
            </div>
        </div>
    </section>
    <!-- presentation video -->
    <section id="distribution" class="text-center p-5">
        <div class="container">
            <div class="row align-items-center justify-content-between">
                <div class="col-md p-2">
                    <iframe width="980" height="420" src="https://www.youtube.com/embed/JhRWBNDdwL0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                </div>
            </div>
        </div>
    </section>
    <!-- gif gallary -->
    <section id="gifs" class="text-center p-5 bg-dark text-light">
        <div class="container">
            <h2><span>Real-time Recognition Result</span></h2>
            <div class="row align-items-center justify-content-between">
                <div class="col-md p-2">
                    <img src="./img/gif/B.gif" class="img-fluid" alt="" />
                </div>
                <div class="col-md p-2">
                    <img src="./img/gif/C.gif" class="img-fluid" alt="" />
                </div>
                <div class="col-md p-2">
                    <img src="./img/gif/F.gif" class="img-fluid" alt="" />
                </div>
            </div>
            <div class="row align-items-center justify-content-between">
                <div class="col-md p-2">
                    <img src="./img/gif/L.gif" class="img-fluid" alt="" />
                </div>
                <div class="col-md p-2">
                    <img src="./img/gif/Q.gif" class="img-fluid" alt="" />
                </div>
                <div class="col-md p-2">
                    <img src="./img/gif/P.gif" class="img-fluid" alt="" />
                </div>
            </div>
        </div>
    </section>
    <!-- introduction  -->
    <section id="intro" class="p-5">
        <div class="container">
            <div class="row align-items-center justify-content-between">
                <div class="col-md">
                    <img src="./img/2_all_hands.png" class="img-fluid" alt="" />
                </div>
                <div class="col-md p-5">
                    <h2>Motivation</h2>
                    <ul>
                        <li>We were inspired from different Music Cultures across the World</li>
                        <li>There are music interpreters at live concerts who translate various music genres such as rap, classical and jazz to ASL</li>
                        <li>We were shocked and never thought music could be translated into Gestures and Expressions.</li>
                    </ul>
                    <h2>Problem</h2>
                    <ul>
                        <li>Sign languages are the <b>native languages</b> of the Deaf community.</li>
                        <li>But it is <b>not common to the general public</b>.</li>
                        <li>By using computer vision techniques, we are hoping to <b>break the wall</b> between the deaf community and the general public.</li>
                    </ul>
                    <a href="https://youtu.be/EuD2iNVMS_4" class="btn btn-outline-danger">
                        <i class="bi bi-youtube"></i> How sign language innovators are bringing music to the deaf?
                    </a>
                </div>
            </div>
        </div>
    </section>
    <!-- dataset section -->
    <section id="dataset" class="p-5 bg-dark text-light">
        <div class="container">
            <div class="row align-items-center justify-content-between">
                <div class="col-md p-5">
                    <h1>Dataset: Sign Language MNIST</h1>
                    <ul class="lead">
                        <li>Label 0-25 one-to-one map for each alphabetic letter A-Z.</li>
                        <li>No cases for 9=J or 25=Z because of gesture motions.</li>
                        <li>27,455 cases training data and 7172 cases test data.</li>
                    </ul>
                    <a href="https://www.kaggle.com/datasets/datamunge/sign-language-mnist" class="btn btn-primary mt-3">
                        <i class="bi bi-chevron-right"></i> View Dataset on Kaggle
                    </a>
                </div>
                <div class="col-md">
                    <img src="./img/8_amer_sign.png" class="img-fluid" alt="" />
                </div>
            </div>
        </div>
    </section>
    <!-- distribution section -->
    <section id="distribution" class="text-center p-5">
        <div class="container">
            <h2><span>Dataset Distribution</span></h2>
            <div class="row align-items-center justify-content-center">
                <div class="col-sm p-0">
                    <img src="./img/5_train_distribution.png" width="500" class="img-fluid" alt="" />
                </div>
                <div class="col-sm p-0">
                    <img src="./img/4_test_distribution.png" width="500" class="img-fluid" alt="" />
                </div>
            </div>
            <div class="row align-items-center justify-content-center">
                <div class="col-sm p-0">
                    <img src="./img/6_train_prop.png" width="500" class="img-fluid" alt="" />
                </div>
                <div class="col-sm p-0">
                    <img src="./img/7_test_prop.png" width="500" class="img-fluid" alt="" />
                </div>
            </div>
        </div>
    </section>
    <!-- method -->
    <section id="method" class="p-5">
        <div class="container">
            <div class="row align-items-center justify-content-between">
                <div class="col-md p-5">
                    <h2>Classification Method</h2>
                    <ul class="lead">
                        <li>We use a CNN model to identify different ASL characters.</li>
                        <li>CNNs are very effective in reducing the number of parameters without losing on the quality of models.</li>
                        <li>We use ReLU as activation fuction and include drop out layers in our network.</li>
                    </ul>
                    <a href="https://github.com/whuang288alex/sign_language/" class="btn btn-outline-dark mt-3">
                        <i class="bi bi-github"></i> Github
                    </a>
                </div>
                <div class="col-md">
                    <img src="./img/9_conv.png" width="500" class="img-fluid" alt="" />
                </div>
            </div>
        </div>
    </section>

    <!-- structure -->
    <section id="structure" class="p-5">
        <div class="container">
            <div class="row align-items-center justify-content-between">
                <div class="col-md p-5">
                    <h2>Model Structure</h2>
                    <ul class="lead">
                        <li>Five levels of convolution layers.</li>
                        <li>Each followed by a maxpooling layer and activated with ReLU.</li>
                        <li>Connected a DropOut layer after five convolution groups to prevent overfitting.</li>
                        <li>Flatten output, connect to fully connected layers, ended by a softmax layer</li>
                    </ul>
                </div>
                <div class="col-md">
                    <img src="./img/10_model_accuracy.png" width="500" class="img-fluid" alt="" />
                </div>
            </div>
            <div class="overflow-auto" style="max-width: device-width;">
                <img src="./img/9_net_structure.png">
            </div>
        </div>
    </section>

    <!-- tracking -->
    <section id="track" class="p-5">
        <div class="container">
            <div class="row align-items-center justify-content-between">
                <div class="col-md p-5">
                    <h2>Hand Tracking</h2>
                    <ul class="lead">
                        <li><b>OpenCV</b> framework and <b>MediaPipe</b> library.</li>
                        <li>Locate hand location, cut the current frame, preprocess the hand frame, put it to omodel, predict the result, display the predicted text on our video frame.</li>
                    </ul>
                    <a href="https://google.github.io/mediapipe/solutions/hands" class="btn btn-outline-dark mt-3">
                        <i class="bi bi-github"></i> MediaPipe
                    </a>
                </div>
                <div class="col-md">
                    <img src="./img/10_hand_landmarks.png" width="500" class="img-fluid" alt="" />
                </div>
            </div>
        </div>
    </section>
    <!-- discussion -->
    <section id="dis" class="p-5">
        <div class="container">
            <div class="row align-items-center justify-content-between">
                <div class="col-md p-5">
                    <h2>Constraints</h2>
                    <ul class="lead">
                        <li>Although the accuracy on test data is about 95%, real time translation results are less accurate.</li>
                        <li>The backgroud lighting and shadow might be the reason of the problem.</li>
                    </ul>
                    <h2>Future Improvements</h2>
                    <ul class="lead">
                        <li>More Data Samples and Varieties?</li>
                        <li>Background noises, image augmentation.</li>
                    </ul>
                </div>
            </div>
        </div>
    </section>
    <!-- citation -->
    <section id="cite" class="p-5">
        <div class="container">
            <h2 class="text-center mb-4">Citation</h2>
            <ol class="list-group list-group-numbered">
                <li class="list-group-item">Sign Language MNIST: Drop-In Replacement for MNIST for Hand Gesture Recognition Tasks. https://www.kaggle.com/datasets/datamunge/sign-language-mnist</li>
                <li class="list-group-item">Lugaresi, C., Tang, J., Nash, H., McClanahan, C., Uboweja, E., Hays, M., Zhang, F., Chang, C.L., Yong, M., Lee, J., Chang, W.T., Hua, W., Georg, M., & Grundmann, M.. MediaPipe: A Framework for Building Perception Pipelines. https://google.github.io/mediapipe/solutions/hands.html</li>
                <li class="list-group-item">Baeldung, How ReLU and Dropout Layers Work in CNNs, https://www.baeldung.com/cs/ml-relu-dropout-layers#:~:text=As%20a%20consequence%2C%20the%20usage,adding%20extra%20ReLUs%20increases%20linearly</li>
                <li class="list-group-item">Mihir Garimella, Sign Language Recognition with Advanced Computer Vision. https://towardsdatascience.com/sign-language-recognition-with-advanced-computer-vision-7b74f20f3442</li>
                <li class="list-group-item">Adrian Rosebrock, OpenCV Stream video to web browser page. https://pyimagesearch.com/2019/09/02/opencv-stream-video-to-web-browser-html-page/</li>
                </ol>
        </div>
    </section>
    <!-- question -->
    <section id="questions" class="p-5">
        <div class="container">
            <h2 class="text-center mb-4">Frequently Asked Questions</h2>
            <div class="accordion accordion-flush" id="questions">
                <!-- Item 1 -->
                <div class="accordion-item">
                    <h2 class="accordion-header">
                        <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#question-one">
                            Why Using ReLU instead of Sigmoidal Functions?
                        </button>
                    </h2>
                    <div id="question-one" class="accordion-collapse collapse" data-bs-parent="#questions">
                        <div class="accordion-body">
                            1. ReLU is very simple to calculate, as it involves only a comparison between its input and the value 0.
                            2. It also has a derivative of either 0 or 1, depending on whether its input is respectively negative or not.
                            The latter, in particular, has important implications for backpropagation during training. It means in fact that calculating the gradient of a neuron is computationally inexpensive.
                            Non-linear activation functions such as the sigmoidal functions, on the contrary, donâ€™t generally have this characteristic.
                            As a consequence, the usage of ReLU helps to prevent the exponential growth in the computation required to operate the neural network. If the CNN scales in size, the computational cost of adding extra ReLUs increases linearly.
                        </div>
                    </div>
                </div>     
                <!-- Item 2 -->
                <div class="accordion-item">
                    <h2 class="accordion-header">
                        <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#question-2">
                            How to load customized dataset in PyTorch?
                        </button>
                    </h2>
                    <div id="question-2" class="accordion-collapse collapse" data-bs-parent="#questions">
                        <div class="accordion-body">
                            In order to use those in Pytorch, we create a custom dataset class using the tutorial found on their 
                            <a href="https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"> offical website</a>.
                        </div>
                    </div>
                </div>     
                <!-- Item 3 -->
                <div class="accordion-item">
                    <h2 class="accordion-header">
                        <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#question-3">
                            How to host website with Github.io?
                        </button>
                    </h2>
                    <div id="question-3" class="accordion-collapse collapse" data-bs-parent="#questions">
                        <div class="accordion-body">
                            In order to host a website with Github, please go to tutorial found on their 
                            <a href="https://pages.github.com"> offical website</a>.
                        </div>
                    </div>
                </div>   
                
            </div>
        </div>
    </section>
    <!-- Footer -->
    <footer class="p-5 bg-dark text-white text-center position-relative">
        <div class="container">
            <p>Copyright &copy; 2022 Alex Huang & Xizheng Yu</p>
    
            <a href="#" class="position-absolute bottom-0 end-0 p-5">
                <i class="bi bi-arrow-up-circle h1"></i>
            </a>
        </div>
    </footer>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-kenU1KFdBIe4zVF0s0G1M5b4hcpxyD9F7jL+jjXkk+Q2h455rYXK/7HAuoJl+0I4" crossorigin="anonymous"></script>

</body>
</html>